<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=6.6.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.6.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.6.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.6.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.6.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.6.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta property="og:type" content="website">
<meta property="og:title" content="X">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="X">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="X">



  <link rel="alternate" href="/atom.xml" title="X" type="application/atom+xml">




  <link rel="canonical" href="http://yoursite.com/page/2/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>X</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <a href="https://github.com/ZSDDZA" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">X</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">x</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-schedule">

    
    
    
      
    

    

    <a href="/schedule/" rel="section"><i class="menu-item-icon fa fa-fw fa-calendar"></i> <br>日程表</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-sitemap">

    
    
    
      
    

    

    <a href="/sitemap.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br>站点地图</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/29/keras-layers-核心网络层摘要/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="X">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="X">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/02/29/keras-layers-核心网络层摘要/" class="post-title-link" itemprop="url">keras.layers--核心网络层摘要</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2020-02-29 23:20:58 / 修改时间：23:21:35" itemprop="dateCreated datePublished" datetime="2020-02-29T23:20:58+08:00">2020-02-29</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>完成一定实践后仔细阅读keras文档，做了关于核心网络层的一些摘要，主要汇总一些常用的网络层及其使用指南，大都在实践中使用过。</p>
<hr>
<p><strong>Dense</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Dense(units, activation=<span class="keyword">None</span>, use_bias=<span class="keyword">True</span>,</span><br><span class="line">                 kernel_initializer=<span class="string">'glorot_uniform'</span>, </span><br><span class="line">                 bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="keyword">None</span>, </span><br><span class="line">                 bias_regularizer=<span class="keyword">None</span>, activity_regularizer=<span class="keyword">None</span>, </span><br><span class="line">                 kernel_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>简要</li>
</ul>
<blockquote>
<p>全连接层。</p>
<p><em>output = activation(dot(input, kernel) + bias)</em>  其中 <em>activation</em> 是按逐个元素计算的激活函数，<em>kernel</em> 是由网络层创建的权值矩阵，以及 <em>bias</em> 是其创建的偏置向量 (只在 <em>use_bias</em><br>为 <em>True</em> 时才有用)。</p>
<p>如果该层的输入的秩大于2，那么它首先被展平然后 再计算与 kernel 的点乘。</p>
</blockquote>
<ul>
<li>重要参数</li>
</ul>
<blockquote>
<p>units: 正整数，输出空间维度。<br>activation: 激活函数。若不指定，则不使用激活函数 (即「线性」激活: a(x)=x。<br>use_bias: 布尔值，该层是否使用偏置向量。</p>
</blockquote>
<ul>
<li>输入输出</li>
</ul>
<blockquote>
<p>输入尺寸：<br>nD 张量，尺寸: (batch_size, …, input_dim)。 最常见的情况是一个尺寸为 (batch_size, input_dim) 的 2D 输入。<br>输出尺寸：<br>nD 张量，尺寸: (batch_size, …, units)。 例如，对于尺寸为 (batch_size, input_dim) 的 2D 输入， 输出的尺寸为 (batch_size, units)。</p>
</blockquote>
<hr>
<p><strong>Activation</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Activation(activation)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>摘要</p>
<blockquote>
<p>激活函数可单独作为一层，也可以嵌入在Dense层中，发挥作用。</p>
</blockquote>
</li>
<li><p>输入输出</p>
<blockquote>
<p>输入尺寸：<br>任意尺寸。 当使用此层作为模型中的第一层时， 使用参数 input_shape （整数元组，不包括样本数的轴）。<br>输出尺寸：<br>与输入相同。</p>
</blockquote>
</li>
</ul>
<hr>
<p><strong>Dropout</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Dropout(rate, noise_shape=<span class="keyword">None</span>, seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>摘要<blockquote>
<p>Dropout 包括在训练中每次更新时， 将输入单元的按比率随机设置为 0， 这有助于防止过拟合。随机舍去一定的神经元，来降低过拟合程度。</p>
</blockquote>
</li>
<li>重要参数<blockquote>
<p>rate: 在 0 和 1 之间浮动。需要丢弃的输入比例。<br>noise_shape: 1D 整数张量， 表示将与输入相乘的二进制 dropout 掩层的形状。 例如，如果你的输入尺寸为 (batch_size, timesteps, features)，然后 你希望 dropout 掩层在所有时间步都是一样的， 你可以使用 noise_shape=(batch_size, 1, features)。<br>seed: 一个作为随机种子的 Python 整数。</p>
</blockquote>
</li>
</ul>
<hr>
<p><strong>Flatten</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Flatten(data_format=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>摘要<blockquote>
<p>将输入展平。不影响批量大小。</p>
</blockquote>
</li>
<li>重要参数<blockquote>
<p>data_format：一个字符串，其值为 channels_last（默认值）或者 channels_first。它表明输入的维度的顺序。此参数的目的是当模型从一种数据格式切换到另一种数据格式时保留权重顺序。channels_last 对应着尺寸为 (batch, …, channels) 的输入，而 channels_first 对应着尺寸为 (batch, channels, …) 的输入。默认为 image_data_format 的值，你可以在 Keras 的配置文件 ~/.keras/keras.json 中找到它。如果你从未设置过它，那么它将是 channels_last</p>
</blockquote>
</li>
</ul>
<hr>
<p><strong>Lambda</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Lambda(function, output_shape=<span class="keyword">None</span>, mask=<span class="keyword">None</span>, arguments=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure></p>
<ul>
<li>摘要<blockquote>
<p>将任意表达式封装为 Layer 对象。</p>
</blockquote>
</li>
<li>重要参数<blockquote>
<p>function: 需要封装的函数。 将输入张量作为第一个参数。<br>output_shape: 预期的函数输出尺寸。 只在使用 Theano 时有意义。 可以是元组或者函数。 如果是元组，它只指定第一个维度； 样本维度假设与输入相同： output_shape = (input_shape[0], ) + output_shape 或者，输入是 None 且样本维度也是 None： output_shape = (None, ) + output_shape 如果是函数，它指定整个尺寸为输入尺寸的一个函数： output_shape = f(input_shape)<br>arguments: 可选的需要传递给函数的关键字参数。</p>
</blockquote>
</li>
<li>输入输出<blockquote>
<p>输入尺寸：<br>任意。当使用此层作为模型中的第一层时， 使用参数 input_shape （整数元组，不包括样本数的轴）。<br>输出尺寸：<br>由 output_shape 参数指定 (或者在使用 TensorFlow 时，自动推理得到)。</p>
</blockquote>
</li>
</ul>
<hr>
<p><strong>Conv2D</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Conv2D(filters, kernel_size, strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                    padding=<span class="string">'valid'</span>, data_format=<span class="keyword">None</span>,</span><br><span class="line">                    dilation_rate=(<span class="number">1</span>, <span class="number">1</span>), activation=<span class="keyword">None</span>,</span><br><span class="line">                    use_bias=<span class="keyword">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>,</span><br><span class="line">                    bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="keyword">None</span>,</span><br><span class="line">                    bias_regularizer=<span class="keyword">None</span>, activity_regularizer=<span class="keyword">None</span>,</span><br><span class="line">                    kernel_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>摘要<blockquote>
<p>2D 卷积层 (例如对图像的空间卷积)。<br>该层创建了一个卷积核， 该卷积核对层输入进行卷积， 以生成输出张量。 如果 use_bias 为 True， 则会创建一个偏置向量并将其添加到输出中。 最后，如果 activation 不是 None，它也会应用于输出。<br>当使用该层作为模型第一层时，需要提供 input_shape 参数 （整数元组，不包含样本表示的轴），例如， input_shape=(128, 128, 3) 表示 128x128 RGB 图像， 在 data_format=”channels_last” 时。</p>
</blockquote>
</li>
<li><p>重要参数</p>
<blockquote>
<p>filters: 整数，输出空间的维度 （即卷积中滤波器的输出数量）。<br>kernel_size: 一个整数，或者 2 个整数表示的元组或列表， 指明 2D 卷积窗口的宽度和高度。 可以是一个整数，为所有空间维度指定相同的值。<br>strides: 一个整数，或者 2 个整数表示的元组或列表， 指明卷积沿宽度和高度方向的步长。 可以是一个整数，为所有空间维度指定相同的值。 指定任何 stride 值 != 1 与指定 dilation_rate 值 != 1 两者不兼容。<br>padding: “valid” 或 “same” (大小写敏感)。</p>
</blockquote>
</li>
<li><p>输入输出</p>
<blockquote>
<p>输入尺寸：<br>如果 data_format=’channels_first’， 输入 4D 张量，尺寸为 (samples, channels, rows, cols)。<br>如果 data_format=’channels_last’， 输入 4D 张量，尺寸为 (samples, rows, cols, channels)。<br>输出尺寸：<br>如果 data_format=’channels_first’， 输出 4D 张量，尺寸为 (samples, filters, new_rows, new_cols)。<br>如果 data_format=’channels_last’， 输出 4D 张量，尺寸为 (samples, new_rows, new_cols, filters)。</p>
</blockquote>
</li>
</ul>
<hr>
<p><strong>MaxPooling2D</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                          strides=<span class="keyword">None</span>, padding=<span class="string">'valid'</span>,</span><br><span class="line">                          data_format=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>摘要<blockquote>
<p>对于空间数据的最大池化。</p>
</blockquote>
</li>
<li>重要参数<blockquote>
<p>pool_size: 整数，或者 2 个整数表示的元组， 沿（垂直，水平）方向缩小比例的因数。 （2，2）会把输入张量的两个维度都缩小一半。 如果只使用一个整数，那么两个维度都会使用同样的窗口长度。</p>
</blockquote>
</li>
</ul>
<p><strong>*AveragePooling2D</strong>与之相似不过完成的是平均池化操作。*</p>
<hr>
<p><strong>SimpleRNN</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.SimpleRNN(units, activation=<span class="string">'tanh'</span>, use_bias=<span class="keyword">True</span>,</span><br><span class="line">                       kernel_initializer=<span class="string">'glorot_uniform'</span>,</span><br><span class="line">                       recurrent_initializer=<span class="string">'orthogonal'</span>, </span><br><span class="line">                       bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="keyword">None</span>, </span><br><span class="line">                       recurrent_regularizer=<span class="keyword">None</span>, bias_regularizer=<span class="keyword">None</span>,</span><br><span class="line">                       activity_regularizer=<span class="keyword">None</span>, kernel_constraint=<span class="keyword">None</span>, </span><br><span class="line">                       recurrent_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>, </span><br><span class="line">                       dropout=<span class="number">0.0</span>, recurrent_dropout=<span class="number">0.0</span>, </span><br><span class="line">                       return_sequences=<span class="keyword">False</span>, return_state=<span class="keyword">False</span>, </span><br><span class="line">                       go_backwards=<span class="keyword">False</span>, stateful=<span class="keyword">False</span>, unroll=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>摘要</li>
</ul>
<blockquote>
<p>全连接的 RNN，其输出将被反馈到输入。</p>
<ul>
<li>重要参数<br>input_dim: 输入的维度（整数）。 将此层用作模型中的第一层时，此参数（或者，关键字参数 input_shape）是必需的。</li>
<li>输入输出<br>输入尺寸：<br>3D 张量，尺寸为 (batch_size, timesteps, input_dim)。<br>输出尺寸：</li>
<li>如果 return_state：返回张量列表。 第一个张量为输出。剩余的张量为最后的状态， 每个张量的尺寸为 (batch_size, units)。</li>
<li>如果 return_sequences：返回 3D 张量， 尺寸为 (batch_size, timesteps, units)。</li>
<li>否则，返回尺寸为 (batch_size, units) 的 2D 张量。</li>
</ul>
<hr>
<p><strong>LSTM</strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.LSTM(units, activation=<span class="string">'tanh'</span>, </span><br><span class="line">                  recurrent_activation=<span class="string">'hard_sigmoid'</span>, use_bias=<span class="keyword">True</span>, </span><br><span class="line">                  kernel_initializer=<span class="string">'glorot_uniform'</span>, </span><br><span class="line">                  recurrent_initializer=<span class="string">'orthogonal'</span>, </span><br><span class="line">                  bias_initializer=<span class="string">'zeros'</span>, unit_forget_bias=<span class="keyword">True</span>, </span><br><span class="line">                  kernel_regularizer=<span class="keyword">None</span>, recurrent_regularizer=<span class="keyword">None</span>, </span><br><span class="line">                  bias_regularizer=<span class="keyword">None</span>, activity_regularizer=<span class="keyword">None</span>, </span><br><span class="line">                  kernel_constraint=<span class="keyword">None</span>, recurrent_constraint=<span class="keyword">None</span>, </span><br><span class="line">                  bias_constraint=<span class="keyword">None</span>, dropout=<span class="number">0.0</span>, recurrent_dropout=<span class="number">0.0</span>, </span><br><span class="line">                  implementation=<span class="number">1</span>, return_sequences=<span class="keyword">False</span>, </span><br><span class="line">                  return_state=<span class="keyword">False</span>, go_backwards=<span class="keyword">False</span>, stateful=<span class="keyword">False</span>, unroll=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>摘要<blockquote>
<p>长短期记忆网络层</p>
</blockquote>
</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

      <div>
       
      </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/19/卷积知识小结/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="X">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="X">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/02/19/卷积知识小结/" class="post-title-link" itemprop="url">卷积知识小结</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2020-02-19 23:59:04 / 修改时间：23:59:26" itemprop="dateCreated datePublished" datetime="2020-02-19T23:59:04+08:00">2020-02-19</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>简单接触了一些卷积神经网络的知识，在此小结一下。由于它的一般应用于图像分类领域，所以在此不便详细图文并茂的解释，只是浅谈一些自己积累到的小知识点。关于卷积神经网络的入门级知识，我推荐<a href="https://zhuanlan.zhihu.com/p/27908027" target="_blank" rel="noopener">前往这里了解</a>。</p>
<hr>
<p>我们知道cnn其实就是在做一个特征提取器的工作。计算过程就是一个累乘累加的过程。将卷积核的</p>
<h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><ul>
<li>卷积神经网络：（卷积层+（可选）池化层）<em>N+全连接层</em>M</li>
<li>全卷积神经网络：（卷积层+（可选）池化层）<em>N+反卷积层</em>M</li>
</ul>
<p>由于卷积层和池化层一般情况下会使输出的尺寸不断变小提取出抽象的特征，由此可以用来处理分类问题。而全卷积神经网络将最后的全连接层全部换成反卷积层，使得我们可以得到和输入图片尺寸相同的输出，从而完成图片的物体分割工作。</p>
<h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>卷积解决了以下问题：</p>
<p>比如在图像分类问题中，网络由全连接层组成就会导致<strong>参数过多</strong>。会浪费我们的计算资源，并且能承载很大信息量的神经网络会轻易模拟出数据中的规律，而产生过拟合，降低模型的泛化能力。</p>
<h3 id="卷积核"><a href="#卷积核" class="headerlink" title="卷积核"></a>卷积核</h3><p>卷积如何解决问题涉及到卷积核的一部分内容，首先不得不提到我们必须了解的卷积神经网络的两个重要性质：</p>
<ul>
<li><p>[ ] 局部链接</p>
<p>输出单元单元通过卷积核与原图进行连接操作，而卷积核的大小一般不会太大所以减少了连接数目，一定程度上缓解了问题。</p>
</li>
<li>[ ] 参数共享</li>
</ul>
<p>卷积核一次只能和原图相同尺寸的区域产生来连接，而其余的地方采用滑动窗口的方式依次连接，也就是说卷积核前后是不变的，只是按规定的步长进行移动来生成最终的feature map。</p>
<p>经过以上两部分的操作可以大大降低参数过多的问题。</p>
<p>我们使用卷积其实是提取到特征，那这两种操作虽然解决了一些问题，但是否会对我们的特征提取产生影响呢？继续看图像处理的例子，比如人脸识别中脸颊部分的像素相近，嘴唇部分的像素相近，也就是说这样的图片是有信息冗余的，由此可见图像是有一定的区域性，所以在经过局部连接之后，仍然能够保留提取特征的能力。而特征应该还与其所在的位置无关，也就是说，假如人脸在图片的右下角或左上角，对于脸部的特征不论出现在图片的什么位置，都应该被识别出来，而参数共享就恰好对应了这一特点，使得无论这一特征出现在什么位置都会得到好的匹配结果。只能匹配到固定位置的特征毫无疑问就是一种过拟合的表现，而恰恰参数共享避免了这种情况。</p>
<h3 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h3><p>卷积后的数据量减小了，但仍然过于庞大，池化操作就是在减少数据量。池化分为最大值池化和平均池化。最常用的是最大值池化，我们主要介绍这种。最大池化保留了每一个小块内的最大值，所以它相当于保留了这一块最佳匹配结果。这也就意味着它不会具体关注窗口内到底是哪一个地方匹配了，而只关注是不是有某个地方匹配上了。这也就能够看出，CNN能够发现图像中是否具有某种特征，而不用在意到底在哪里具有这种特征（似乎和参数共享有类似的作用）。</p>
<h3 id="非线性激活"><a href="#非线性激活" class="headerlink" title="非线性激活"></a>非线性激活</h3><p>激活函数比如Relu，它的公式：$f(x)=max(0,x)$即，保留大于等于0的值，其余所有小于0的数值直接改写为0。卷积后的图中的值，越小则越不相关，我们进行特征提取时，为了使得数据更少，操作更方便，就直接舍弃掉那些不相关联的数据（直接取零）。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

      <div>
       
      </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/12/HDF5-python-使用简介/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="X">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="X">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/02/12/HDF5-python-使用简介/" class="post-title-link" itemprop="url">HDF5--python 使用简介</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2020-02-12 23:52:23 / 修改时间：23:56:28" itemprop="dateCreated datePublished" datetime="2020-02-12T23:52:23+08:00">2020-02-12</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>引：在使用TensorFlow，学习回调函数时，使用了ModelCheckpoint()，产生了.h5的文件。为了了解回调函数产生的信息，需要了解HDF5的相关内容，以及在python中的使用与相关问题解决。</em><br>文中一些叙述为了方便初次接触者理解，表述并不严谨，仅供简单参考。</p>
<hr>
<h2 id="初次见面"><a href="#初次见面" class="headerlink" title="初次见面"></a>初次见面</h2><p>HDF5（Hierarchical Data Formal）是用于存储大规模数值数据的较为理想的存储格式，文件后缀名为h5，存储读取速度非常快，且可在文件内部按照明确的层次存储数据，同一个HDF5可以看做一个高度整合的文件夹，其内部可存放不同类型的数据。</p>
<p>在Python中操纵HDF5文件的方式主要有两种</p>
<ul>
<li>是利用<strong>pandas</strong>中内建的一系列HDF5文件操作相关的方法，来完成相关操作。</li>
<li>二是利用<strong>h5py</strong>模块来完成Python原生数据结构与HDF5格式的转化</li>
</ul>
<p>本篇主要介绍hdf5的基础内容和对应模块使用的快速入门。</p>
<h2 id="初遇时的差池"><a href="#初遇时的差池" class="headerlink" title="初遇时的差池"></a>初遇时的差池</h2><p><del>一段小插曲</del><br>HDF是HDF(Hierarchical Data File)是美国国家高级计算应用中心(National Center for Supercomputing Application,NCSA)为了满足各种领域研究需求而研制的一种能高效存储和分发科学数据的新型数据格式 。阅读的文档中提到了到国家卫星气象中心（NSMC）曾经发布过一份《HDF5.0 使用简介》,抱着些许迷信权威的心态阅读后发现它涉及的信息就我目前来说价值不大，其中主要有讲HDF5文件的组织，API，创建，数据集数据空间，组群，属性等等，内容大而全，但似乎这篇教材发布的相对较早，所以产生了一定的局限性并且内部的相关URL都失效了，它本身也在国家卫星气象中心的官网上没有什么存在的痕迹。相关的API只涉及了C和FORTRAN的外壳包装函数。对于像我这样在使用python且第一次接触HDF5的使用者并不友好，索性只读了开头的基础内容并建立了更详细的认知后就放弃了继续阅读的打算。</p>
<h2 id="相识"><a href="#相识" class="headerlink" title="相识"></a>相识</h2><p>首先从hdf5文件讲起。</p>
<p>HDF5文件具有两类存储对象，dataset和group。dataset是类似于数组的数据集，而group是类似文件夹一样的容器，存放dataset和其他group。</p>
<p>HDF本意即是<strong>层次数据格式</strong>，所以就其存储结构来说是类似与POSIX风格的。其实现的方式就是group。每层都用’/‘分隔。我们创建的file object其实也可以看作一个group，是一个root group，其余的groups可以称为subgroups。</p>
<p>dataset与numpy中的array相似，比如都具有shape、dtype、以及一些切片操作等。虽然与Numpy的数组在接口上很相近，但是支持更多对外透明的存储特征，如数据压缩，误差检测，分块传输。</p>
<p>HDF5的一个很好的features就是可以在数据旁边存储元数据<sup><a href="#fn_1" id="reffn_1">1</a></sup>。所有的group和dataset都支持叫做<strong>属性</strong>的数据形式。</p>
<h4 id="h5py"><a href="#h5py" class="headerlink" title="h5py"></a>h5py</h4><p>想到python一定有对应的文件解析库，于是我开始了h5py的“快速”入门。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">import h5py</span><br><span class="line"># 读取</span><br><span class="line">file = h5py.File(&apos;test.hdf5&apos;, &apos;r&apos;)# .hdf5与.h5意义相同</span><br><span class="line"># 一下也可以完成读取</span><br><span class="line">with h5py.File(&quot;mytestfile.hdf5&quot;, &quot;w&quot;) as f:</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"># 我们需要注意的是group（包括File对象）与python中的字典相似</span><br><span class="line"># 通过该方法可以获得对应group下的subgroups或datasets，返回包含字符串的列表</span><br><span class="line">f.keys()</span><br><span class="line"></span><br><span class="line"># 此时我们假设存在一个名为DataSet的dataset对象</span><br><span class="line"># 利用对应键来索引值的方法可以获取该对象</span><br><span class="line">dest = f[&apos;DataSet&apos;]</span><br><span class="line"></span><br><span class="line"># dataset对象满足我们平时使用的numpy数组的一些操作，如下：</span><br><span class="line">dest.shape</span><br><span class="line">dest.dtype</span><br><span class="line">dest[:]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 创建HDF5文件</span><br><span class="line">f = h5py.File(&apos;test.h5&apos;, &apos;w&apos;)</span><br><span class="line"></span><br><span class="line"># 使用create_dataset创建给定形状和数据类型的空dataset</span><br><span class="line">dataset = f.create_dataset(&apos;DS&apos;,(100,), dtype=&apos;i&apos;)</span><br><span class="line"># 也可以使用numpy中数组来初始化</span><br><span class="line">array = np.arange(100)</span><br><span class="line">dataset = f.create_dataset(&apos;init&apos;, data=array)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 分块存储</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">在缺省设置下，HDF5数据集在内存中是连续布局的，也就是按照传统的C序。</span><br><span class="line">Dataset也可以在HDF5的分块存储布局下创建。</span><br><span class="line">也就是dataset被分为大小相同的若干块随意地分布在磁盘上，并使用B树建立索引。</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line"># 为了进行分块存储，将关键字设为一个元组来指示块的形状。</span><br><span class="line">dset = f.create_dataset(&quot;chunked&quot;, (1000, 1000), chunks=(100, 100))</span><br><span class="line"># 也可以自动分块，不必指定块的形状。</span><br><span class="line">dset = f.create_dataset(&quot;autochunk&quot;, (1000, 1000), chunks=True)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 分层结构</span><br><span class="line"># 遍历subgroups</span><br><span class="line">for name in f:</span><br><span class="line">    print(name)</span><br><span class="line"># 递归遍历所有subgroups</span><br><span class="line">def print_name(name):</span><br><span class="line">    print(name)</span><br><span class="line"></span><br><span class="line">f.visit(print_name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 属性通过attrs成员访问，类似于python中词典格式。</span><br><span class="line"> dataset.attrs[&apos;bias&apos;] = 60</span><br><span class="line"> &apos;bias&apos; in dataset.attrs</span><br></pre></td></tr></table></figure>
<p>一些其他的特性</p>
<ol>
<li>滤波器组<br>HDF5的滤波器组能够对分块数组进行变换。最常用的变换是高保真压缩。使用一个特定的压缩滤波器创建dataset之后，读写都可以向平常一样，不必添加额外的步骤。<br>用关键词compression来指定压缩滤波器，而滤波器的可选参数使用关键词compression_opt来指定：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dset = f.create_dataset(&quot;zipped&quot;, (100, 100), compression=&quot;gzip&quot;)</span><br></pre></td></tr></table></figure>
<ol>
<li>HDF5文件的限制</li>
</ol>
<ul>
<li>HDF5文件本身大小没有限制，但是HDF5的一个dataset最高允许32个维，每个维度最多可有2^64个值，每个值大小理论上可以任意大</li>
<li>目前一个chunk允许的最大容量为2^32-1 byte (4GB). 大小固定的dataset的块的大小不能超过dataset的大小。</li>
</ul>
<p><a href="http://docs.h5py.org/en/latest/index.html" title="HDF5 for Python -- h5py 2.10.0 doc" target="_blank" rel="noopener">更多信息</a></p>
<h4 id="pandas"><a href="#pandas" class="headerlink" title="pandas"></a>pandas</h4><p><strong> 写出 </strong></p>
<p>　　pandas中的HDFStore()用于生成管理HDF5文件IO操作的对象，其主要参数如下：</p>
<p>　　path：字符型输入，用于指定h5文件的名称（不在当前工作目录时需要带上完整路径信息）</p>
<p>　　mode：用于指定IO操作的模式，与Python内建的open()中的参数一致，默认为’a’，即当指定文件已存在时不影响原有数据写入，指定文件不存在时则新建文件；’r’，只读模式；’w’，创建新文件（会覆盖同名旧文件）；’r+’，与’a’作用相似，但要求文件必须已经存在；</p>
<p>　　complevel：int型，用于控制h5文件的压缩水平，取值范围在0-9之间，越大则文件的压缩程度越大，占用的空间越小，但相对应的在读取文件时需要付出更多解压缩的时间成本，默认为0，代表不压缩</p>
<p>　　下面我们创建一个HDF5 IO对象store：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">store = pd.HDFStore(<span class="string">'demo.h5'</span>)</span><br><span class="line"><span class="string">'''查看store类型'''</span></span><br><span class="line">print(store)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">pandas</span>.<span class="title">io</span>.<span class="title">pytables</span>.<span class="title">HDFStore</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">File</span> <span class="title">path</span>:</span> demo.h5</span><br></pre></td></tr></table></figure>
<p>可以看到store对象属于pandas的io类，通过上面的语句我们已经成功的初始化名为demo.h5的的文件，本地也相应的出现了对应文件。</p>
<p>接下来我们创建pandas中不同的两种对象，并将它们共同保存到store中，首先创建series对象：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个series对象</span></span><br><span class="line">s = pd.Series(np.random.randn(<span class="number">5</span>), index=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'e'</span>])</span><br><span class="line"><span class="comment">#创建一个dataframe对象</span></span><br><span class="line">df = pd.DataFrame(np.random.randn(<span class="number">8</span>, <span class="number">3</span>),</span><br><span class="line">                 columns=[<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>])</span><br></pre></td></tr></table></figure>
<p>第一种方式利用键值对将不同的数据存入store对象中，这里为了代码简洁使用了元组赋值法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">store[<span class="string">'s'</span>],store[<span class="string">'df'</span>] = s,df</span><br></pre></td></tr></table></figure>
<p>第二种方式利用store对象的put()方法，其主要参数如下：</p>
<p>　　key：指定h5文件中待写入数据的key</p>
<p>　　value：指定与key对应的待写入的数据</p>
<p>　　format：字符型输入，用于指定写出的模式，’fixed’对应的模式速度快，但是不支持追加也不支持检索；’table’对应的模式以表格的模式写出，速度稍慢，但是支持直接通过store对象进行追加和表格查询操作</p>
<p>使用put()方法将数据存入store对象中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">store.put(key=<span class="string">'s'</span>,value=s);store.put(key=<span class="string">'df'</span>,value=df)</span><br></pre></td></tr></table></figure></p>
<p>既然是键值对的格式，那么可以查看store的items属性（注意这里store对象只有items和keys属性，没有values属性）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">store.items</span><br></pre></td></tr></table></figure></p>
<p>调用store对象中的数据直接用对应的键名来索引即可：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">store[<span class="string">'df'</span>]</span><br></pre></td></tr></table></figure></p>
<p>删除store对象中指定数据的方法有两种，一是使用remove()方法，传入要删除数据对应的键：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">store.remove(<span class="string">'s'</span>)</span><br><span class="line">print(store.keys())</span><br></pre></td></tr></table></figure>
<p>　　二是使用Python中的关键词del来删除指定数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">del</span> store[<span class="string">'s'</span>]</span><br><span class="line">print(store.keys())</span><br></pre></td></tr></table></figure>
<p>这时若想将当前的store对象持久化到本地，只需要利用close()方法关闭store对象即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">store.close()</span><br><span class="line"><span class="string">'''查看store连接状况，False则代表已关闭'''</span></span><br><span class="line">store.is_open</span><br><span class="line"><span class="comment"># 这时本地的h5文件也相应的存储进store对象关闭前包含的文件</span></span><br></pre></td></tr></table></figure>
<p>　除了通过定义一个确切的store对象的方式，还可以从pandas中的数据结构直接导出到本地h5文件中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建新的数据框</span></span><br><span class="line">df_ = pd.DataFrame(np.random.randn(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line"><span class="comment">#导出到已存在的h5文件中，这里需要指定key</span></span><br><span class="line">df_.to_hdf(path_or_buf=<span class="string">'demo.h5'</span>,key=<span class="string">'df_'</span>)</span><br><span class="line"><span class="comment">#创建于本地demo.h5进行IO连接的store对象</span></span><br><span class="line">store = pd.HDFStore(<span class="string">'demo.h5'</span>)</span><br><span class="line"><span class="comment">#查看指定h5对象中的所有键</span></span><br><span class="line">print(store.keys())</span><br></pre></td></tr></table></figure>
<p><strong>读入</strong><br>在pandas中读入HDF5文件的方式主要有两种，一是通过上一节中类似的方式创建与本地h5文件连接的IO对象，接着使用键索引或者store对象的get()方法传入要提取数据的key来读入指定数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">store = pd.HDFStore(<span class="string">'demo.h5'</span>)</span><br><span class="line"><span class="string">'''方式1'''</span></span><br><span class="line">df1 = store[<span class="string">'df'</span>]</span><br><span class="line"><span class="string">'''方式2'''</span></span><br><span class="line">df2 = store.get(<span class="string">'df'</span>)</span><br><span class="line">df1 == df2</span><br></pre></td></tr></table></figure>
<p>可以看出这两种方式都能顺利读取键对应的数据。</p>
<p>　　第二种读入h5格式文件中数据的方法是pandas中的read_hdf()，其主要参数如下：</p>
<p>　　path_or_buf：传入指定h5文件的名称</p>
<p>　　key：要提取数据的键</p>
<p>　　需要注意的是利用read_hdf()读取h5文件时对应文件不可以同时存在其他未关闭的IO对象，否则会报错，如下例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(store.is_open)</span><br><span class="line">df = pd.read_hdf(<span class="string">'demo.h5'</span>,key=<span class="string">'df'</span>)</span><br></pre></td></tr></table></figure>
<p>　把IO对象关闭后再次提取：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">store.close()</span><br><span class="line">print(store.is_open)</span><br><span class="line">df = pd.read_hdf(<span class="string">'demo.h5'</span>,key=<span class="string">'df'</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>
<hr>
<p>参考：<br><a href="https://blog.csdn.net/yudf2010/article/details/50353292" target="_blank" rel="noopener">https://blog.csdn.net/yudf2010/article/details/50353292</a><br><a href="https://segmentfault.com/a/119000001667088" target="_blank" rel="noopener">https://segmentfault.com/a/119000001667088</a><br><a href="https://www.cnblogs.com/feffery/p/11135082.html" target="_blank" rel="noopener">https://www.cnblogs.com/feffery/p/11135082.html</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

      <div>
       
      </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/06/激活函数/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="X">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="X">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/02/06/激活函数/" class="post-title-link" itemprop="url">激活函数</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2020-02-06 02:32:07 / 修改时间：12:38:03" itemprop="dateCreated datePublished" datetime="2020-02-06T02:32:07+08:00">2020-02-06</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>借此机会把深度学习中常用的激活函数做一些总结。</p>
<h3 id="激活函数概念"><a href="#激活函数概念" class="headerlink" title="激活函数概念"></a>激活函数概念</h3><p>所谓激活函数（Activation Function），就是在人工神经网络的神经元上运行的函数，负责将神经元的输入映射到输出端。</p>
<h3 id="什么是激活函数"><a href="#什么是激活函数" class="headerlink" title="什么是激活函数"></a>什么是激活函数</h3><p>激活函数（Activation functions）对于人工神经网络模型去学习、理解非常复杂和非线性的函数来说具有十分重要的作用。它们将非线性特性引入到我们的网络中。神经元中，输入的 inputs 通过加权，求和后，还被作用了一个函数，这个函数就是激活函数。引入激活函数是为了增加神经网络模型的非线性。没有激活函数的每层都相当于矩阵相乘。就算你叠加了若干层之后，无非还是个矩阵相乘罢了。</p>
<h3 id="为什么使用激活函数"><a href="#为什么使用激活函数" class="headerlink" title="为什么使用激活函数"></a>为什么使用激活函数</h3><p>如果不用激活函数，每一层输出都是上层输入的线性函数，无论神经网络有多少层，输出都是输入的线性组合，这种情况就是最原始的感知机（Perceptron）。<br>如果使用的话，激活函数给神经元引入了非线性因素，使得神经网络可以任意逼近任何非线性函数，这样神经网络就可以应用到众多的非线性模型中。</p>
<h3 id="个人认知与理解"><a href="#个人认知与理解" class="headerlink" title="个人认知与理解"></a>个人认知与理解</h3><p>我觉得机器学习的传统算法与深度学习算法的比较重要的区别是：</p>
<ol>
<li>从广义上来讲，机器学习的传统算法一般只能使用一种目标模型函数，比如逻辑回归使用logistic函数、只能解决单维度问题；而深度学习可以在不同神经层使用不同或者多种激活函数、因此拥有多种或者不同函数的特性，所以解决问题具有多维度、线性、非线性等处理能力</li>
<li>深度学习的激活函数使得深度学习算法既能解决简单的线性问题、也能处理复杂的非线性问题</li>
<li>数据中的特征往往具有不同的特性、特征与不同模型之间也有较大的辨识差异，机器学习的传统算法的单一模型可能只能对部分特征产生重要作用，而深度学习的多种激活函数则比较全面、多维度对特征进行学习</li>
</ol>
<h3 id="常用的激活函数"><a href="#常用的激活函数" class="headerlink" title="常用的激活函数"></a>常用的激活函数</h3><ol>
<li>sigmoid 函数</li>
<li>tanh 函数</li>
<li>relu 函数</li>
<li>leaky relu 函数</li>
<li>elu 函数</li>
<li>softmax 函数</li>
</ol>
<h3 id="饱和激活函数与非饱和激活函数"><a href="#饱和激活函数与非饱和激活函数" class="headerlink" title="饱和激活函数与非饱和激活函数"></a>饱和激活函数与非饱和激活函数</h3><ol>
<li>饱和函数是指当自变量 x 达到某个值(或者说趋于无穷小、无穷大)的时候，因变量 y 就不再发生变化，而是趋于某一个固定的值</li>
</ol>
<ul>
<li>sigmoid 函数就是一个饱和激活函数，当自变量 z 趋于无穷小时，因变量 y 趋于 0；当自变量 z 趋于无穷大时，因变量 y 趋于 1</li>
<li>tanh 函数就是一个饱和激活函数，当自变量 z 趋于无穷小时，因变量 y 趋于 -1；当自变量 z 趋于无穷大时，因变量 y 趋于 1</li>
</ul>
<ol>
<li>饱和函数是指当自变量 x 达到某个值(或者说趋于无穷小、无穷大)的时候，因变量 y 就依然发生变化，并不是趋于某一个固定的值</li>
</ol>
<ul>
<li>relu 函数就是一个非饱和激活函数，当自变量 z 小于 0 时，因变量 y 等于 0；但当自变量 z 大于 0 时，因变量 y 是一个 z 的变化值</li>
<li>relu 的变种激活函数</li>
</ul>
<ol>
<li>非饱和激活函数的优势</li>
</ol>
<ul>
<li>首先，“非饱和激活函数”能解决所谓的“梯度消失”问题</li>
<li>其次，它能加快收敛速度<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">-10</span>, <span class="number">10</span>, <span class="number">100</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="1-sigmoid激活函数-饱和函数"><a href="#1-sigmoid激活函数-饱和函数" class="headerlink" title="1.sigmoid激活函数(饱和函数)"></a>1.sigmoid激活函数(饱和函数)</h3><p>sigmoid函数计算公式<br>$<br>\sigma(z) =\frac{1}{1+e^{-z}},e\approx 2.7183<br>$<br>sigmoid函数的导数公式<br>$<br>{\sigma(z)}’ =\sigma(z)(1-\sigma(z)),e\approx 2.7183<br>$<br>sigmoid函数评价</p>
<ul>
<li>优点：sigmoid函数有效地将实数域的线性问题映射到[0,1]区间的类别概率问题，实现分类；</li>
<li>缺点：然而在深度学习算法中使用sigmoid函数有时候在反向求导传播时会导致梯度消失的现象：<br>当z很大时，$\sigma(z)$趋近于1，当z很小时，$\sigma(z)$趋近于0<br>其导数${\sigma(z)}’ =\sigma(z)(1-\sigma(z))$在z很大或很小时都会趋近于0，造成梯度消失的现象<h1 id="手写计算函数"><a href="#手写计算函数" class="headerlink" title="手写计算函数"></a>手写计算函数</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z, mode=False)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> mode:  <span class="comment"># 手写公式</span></span><br><span class="line">        L = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(z)):</span><br><span class="line">            sigmoid_value = <span class="number">1</span>/(<span class="number">1</span>+(<span class="number">2.7183</span>)**(-z[i]))</span><br><span class="line">            L.append(sigmoid_value)</span><br><span class="line">        <span class="keyword">return</span> L</span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># 使用numpy</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-z))</span><br><span class="line">plt.plot(x, sigmoid(z=x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用 Tensorflow 的 sigmoid 函数</span></span><br><span class="line">y_sigmoid = tf.nn.sigmoid(x)</span><br><span class="line">plt.plot(x, y_sigmoid)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="2-tanh激活函数-饱和函数"><a href="#2-tanh激活函数-饱和函数" class="headerlink" title="2.tanh激活函数(饱和函数)"></a>2.tanh激活函数(饱和函数)</h3><p>tanh函数计算公式<br>$<br>tanh(z)=\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}},e\approx 2.7183<br>$<br>tanh函数的导数公式<br>$<br>{tanh(z)}’=1-(tanh(z))^{2},e\approx 2.7183<br>$<br>tanh函数评价</p>
<ul>
<li>优点：sigmoid函数有效地将实数域的线性问题映射到[-1,1]区间的类别概率问题，实现分类；</li>
<li>缺点：然而在深度学习算法中使用tanh函数有时候在反向求导传播时会导致梯度消失的现象：<br>当z很大时，tanh(z)\tanh(z)tanh(z)趋近于1，当z很小时，tanh(z)tanh(z)tanh(z)趋近于-1<br>其导数 ${tanh(z)}’=1-(tanh(z))^{2}$在z很大或很小时都会趋近于0，造成梯度消失的现象<br>tanh与sigmoid的关系式：<br>$tanh(z)=2sigmoid(2z)-1$<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tanh</span><span class="params">(z, mode=True)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> mode:  <span class="comment"># 手写公式</span></span><br><span class="line">        L = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(z)):</span><br><span class="line">            exp1 = <span class="number">2.7183</span>**(z[i])</span><br><span class="line">            exp2 = <span class="number">2.7183</span>**(-z[i])</span><br><span class="line">            tanh_value = (exp1-exp2)/(exp1+exp2)</span><br><span class="line">            L.append(tanh_value)</span><br><span class="line">        <span class="keyword">return</span> L</span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># 使用numpy</span></span><br><span class="line">        <span class="keyword">return</span> (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))</span><br><span class="line">plt.plot(x,tanh(z=x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用 Tensorflow 的 tanh 函数</span></span><br><span class="line">y_tanh = tf.nn.tanh(x)</span><br><span class="line">plt.plot(x, y_tanh)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="3-relu激活函数-非饱和函数"><a href="#3-relu激活函数-非饱和函数" class="headerlink" title="3.relu激活函数(非饱和函数)"></a>3.relu激活函数(非饱和函数)</h3><p>修正线性单元（Rectified linear unit，ReLU）</p>
<p>relu函数计算公式<br>$relu(z)=max(0,z)$<br>relu函数的导数公式<br>$<br>{relu(z)}’=\left\{\begin{matrix}1 &amp; z&gt; 0\ 0 &amp; z\leq 0\end{matrix}\right.<br>$<br>relu函数评价</p>
<ul>
<li>优点：<br>relu函数的非饱和性可以有效地解决梯度消失的问题，提供相对较宽的激活边界<br>relu函数是阈值函数，运算简单且快速，只需通过阈值判断就可以得到激活值，而sigmoid、tanh函数都需要计算指数，运算复杂<br>ReLU的单侧抑制(负梯度都为 0)提供了网络的稀疏表达能力</li>
<li>缺点：<br>relu(z)=max(0,z)relu(z)=max(0,z)relu(z)=max(0,z)会导致负梯度的神经元产生不可逆的死亡，也称为死亡神经元，由于负梯度值都为 0，在往后的运算中都将以 0 传播<br>如果学习率（Learning Rate）设置较大，会导致超过一定比例的神经元不可逆死亡，进而参数梯度无法更新，整个训练过程失败<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(x)</span>:</span>  <span class="comment"># 手写公式</span></span><br><span class="line">    relu_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(x)):</span><br><span class="line">        relu_list.append(max(<span class="number">0</span>, x[i]))</span><br><span class="line">    <span class="keyword">return</span> relu_list</span><br><span class="line">plt.ylim(<span class="number">-1</span>,<span class="number">6</span>)</span><br><span class="line">plt.plot(x, relu(x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用 Tensorflow 的 relu 函数</span></span><br><span class="line">y_relu = tf.nn.relu(x)</span><br><span class="line">plt.ylim(<span class="number">-1</span>,<span class="number">6</span>)</span><br><span class="line">plt.plot(x, y_relu)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="4-leaky-relu"><a href="#4-leaky-relu" class="headerlink" title="4.leaky relu"></a>4.leaky relu</h3><p>带泄露修正线性单元（Leaky ReLU）函数是经典（以及广泛使用的）的ReLu激活函数的变体，该函数输出对负值输入有很小的坡度，它旨在解决负梯度神经元死亡的问题。由于负梯度神经元导数总是不为零，这能减少静默神经元的出现，允许基于梯度的学习（虽然会很慢），解决了Relu函数进入负区间后神经元不学习的问题。</p>
<p>leaky relu 函数计算公式<br>$Lrelu(z)=max(0.1z,z),a&lt;1(a=0.1)$,其中a可以自定义</p>
<p>leaky relu 函数的导数公式<br>$<br>{Lrelu(z)}’=\left\{\begin{matrix}1 &amp; z&gt;0\ 0.1 &amp;z\leq 0 \end{matrix}\right.<br>$<br>leaky relu 函数评价</p>
<ul>
<li>优点：<br>旨在解决 relu 负梯度神经元死亡的问题，函数输出对负值输入有很小的坡度<br>解决了Relu函数进入负区间后神经元不学习的问题</li>
<li>缺点：<br>负梯度的 a 难以寻求合适的系数值，a 通常小于 1 且通常使用 a = 0.1<br>负梯度的 a 的选择和确定需要一定的经验或者做实验验证，相对麻烦一些<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leaky_rule</span><span class="params">(z)</span>:</span>  <span class="comment"># 手写公式</span></span><br><span class="line">    L = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(z)):</span><br><span class="line">        lrule_value = max(<span class="number">0.1</span>*z[i], z[i])</span><br><span class="line">        L.append(lrule_value)</span><br><span class="line">    <span class="keyword">return</span> L</span><br><span class="line">plt.plot(x, leaky_rule(z=x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用 Tensorflow 的 leaky_relu 函数</span></span><br><span class="line">y_lrelu = tf.nn.leaky_relu(x)</span><br><span class="line">plt.plot(x, y_lrelu)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="5-elu"><a href="#5-elu" class="headerlink" title="5.elu"></a>5.elu</h3><p>指数线性单元（Exponential Linear Units）</p>
<p>elu 函数计算公式<br>$elu(z)={za(ez−1)z≥0z&lt;0$,tensorflow中,a默认为1</p>
<p>elu 函数的导数公式<br>$<br>{elu(z)}’=\left\{\begin{matrix}1 &amp; z\leq 0\ ae^{z} &amp; z&lt;0\end{matrix}\right.<br>$<br>elu 函数评价</p>
<p>融合了sigmoid和ReLU，左侧具有软饱和性，右侧无饱和性。<br>右侧线性部分使得ELU能够缓解梯度消失，而左侧软饱能够让ELU对输入变化或噪声更鲁棒。<br>ELU的输出均值接近于零，所以收敛速度更快。<br>在 ImageNet上，不加 Batch Normalization 30 层以上的 ReLU 网络会无法收敛，PReLU网络在MSRA的Fan-in （caffe ）初始化下会发散，而 ELU 网络在Fan-in/Fan-out下都能收敛。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">elu</span><span class="params">(z, a=<span class="number">0.1</span>)</span>:</span>  <span class="comment"># 手写公式</span></span><br><span class="line">    L = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(z)):</span><br><span class="line">        <span class="keyword">if</span> z[i] &gt;= <span class="number">0</span>:</span><br><span class="line">            elu_value = z[i]</span><br><span class="line">            L.append(elu_value)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            elu_value = a*(<span class="number">2.7183</span>**(z[i]) - <span class="number">1</span>)</span><br><span class="line">            L.append(elu_value)</span><br><span class="line">    <span class="keyword">return</span> L</span><br><span class="line">plt.plot(x, elu(z=x, a=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用 Tensorflow 的 elu 函数</span></span><br><span class="line">y_elu = tf.nn.elu(x)</span><br><span class="line">plt.plot(x, y_elu)</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

      <div>
       
      </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/03/tensorflow基础/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="X">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="X">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/02/03/tensorflow基础/" class="post-title-link" itemprop="url">tensorflow基础</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2020-02-03 12:11:06" itemprop="dateCreated datePublished" datetime="2020-02-03T12:11:06+08:00">2020-02-03</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2020-02-06 12:11:56" itemprop="dateModified" datetime="2020-02-06T12:11:56+08:00">2020-02-06</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="第一部分：Tensorflow基础"><a href="#第一部分：Tensorflow基础" class="headerlink" title="第一部分：Tensorflow基础"></a>第一部分：Tensorflow基础</h2><h3 id="Tensors张量"><a href="#Tensors张量" class="headerlink" title="Tensors张量"></a>Tensors张量</h3><h4 id="常量constant"><a href="#常量constant" class="headerlink" title="常量constant:"></a>常量constant:</h4><p>‘’’python<br>x = tf.constant([[4,2],[9,5]])<br>print(x)</p>
<p>tf.Tensor(<br>[[4 2]<br> [9 5]], shape=(2, 2), dtype=int32)<br>‘’’</p>
<p>可以通过“.numpy()”来得到numpy array类型</p>
<p>‘’’python<br>x.numpy()</p>
<p>array([[4, 2],<br>       [9, 5]], dtype=int32)<br>‘’</p>
<p>像numpy一样，有shape和dtype属性</p>
<p>‘’’python<br>print(‘shape:’,x.shape)<br>print(‘dx.dtype)</p>
<p>(2, 2)</p>
<p><dtype: 'int32'=""><br>‘’’</dtype:></p>
<p>常用的产生常量的方法是tf.ones和tf.zeros就像numpy的np.ones``np.zeros</p>
<p>‘’’python<br>print(tf.ones(shape=(2,3)))<br>print(tf.zeros(shape=(3,2)))</p>
<p>tf.Tensor(<br>[[1. 1. 1.]<br> [1. 1. 1.]], shape=(2, 3), dtype=float32)<br>tf.Tensor(<br>[[0. 0.]<br> [0. 0.]<br> [0. 0.]], shape=(3, 2), dtype=float32)<br>‘’’</p>
<h3 id="随机数常量random-constant正态分布"><a href="#随机数常量random-constant正态分布" class="headerlink" title="随机数常量random constant正态分布"></a>随机数常量random constant正态分布</h3><p>‘’’python<br>tf.random.normal(shape=(2,2),mean=0,stddev=1.0)</p>
<tf.tensor: id="12," shape="(2," 2),="" dtype="float32," numpy="array([[-0.05229542," 0.64488363],="" [="" 0.37966082,="" 1.0098479="" ]],="">

<h1 id="整数均匀分布"><a href="#整数均匀分布" class="headerlink" title="整数均匀分布"></a>整数均匀分布</h1><p>tf.random.uniform(shape=(2,2),minval=0,maxval=10,dtype=tf.int32)</p>
<p><tf.tensor: id="16," shape="(2," 2),="" dtype="int32," numpy="array([[6," 3],="" [8,="" 7]],=""><br>‘’’</tf.tensor:></p>
<h3 id="Variables变量"><a href="#Variables变量" class="headerlink" title="Variables变量"></a>Variables变量</h3><p>变量是一种特别的张量，用来存储可变数值，需要用一些值来初始化<br>‘’’pyhon<br>initial_value = tf.random.normal(shape=(2,2))<br>a = tf.Variable(initial_value)<br>print(a)</p>
<p><tf.variable 'variable:0'="" shape="(2," 2)="" dtype="float32," numpy="array([[" 0.07630513,="" -0.39769924],="" [-0.9712114="" ,="" -0.62955064]],=""><br>‘’’</tf.variable></p>
<p>可以通过assign(value)来赋值“=”，或assign_add(value)“+=”，或assign_sub(value)“-=”<br>‘’’python<br>new_value = tf.random.normal(shape=(2, 2))<br>a.assign(new_value)<br>for i in range(2):<br>    for j in range(2):<br>        assert a[i, j] == new_value[i, j]</p>
<p>added_value = tf.random.normal(shape=(2,2))<br>a.assign_add(added_value)<br>for i in range(2):<br>    for j in range(2):<br>        assert a[i,j] == new_value[i,j]+added_value[i,j]<br>‘’’</p>
<h3 id="Tensorflow数学运算"><a href="#Tensorflow数学运算" class="headerlink" title="Tensorflow数学运算"></a>Tensorflow数学运算</h3><p>可以像numpy那样做作运算，Tensorflow的不同时这些运算可以放到GPU或TPU上执行<br>‘’’python<br>a = tf.random.normal(shape=(2,2))<br>b = tf.random.normal(shape=(2,2))<br>c = a+b<br>d = tf.square(c)<br>e = tf.exp(c)<br>print(a)<br>print(b)<br>print(c)<br>print(d)<br>print(e)</p>
<p>tf.Tensor(<br>[[ 1.6862711 -1.4246397]<br> [-1.0287055 -1.3188182]], shape=(2, 2), dtype=float32)<br>tf.Tensor(<br>[[ 1.4519434  0.7635907]<br> [ 1.1213834 -1.4559215]], shape=(2, 2), dtype=float32)<br>tf.Tensor(<br>[[ 3.1382146  -0.661049  ]<br> [ 0.09267795 -2.7747397 ]], shape=(2, 2), dtype=float32)<br>tf.Tensor(<br>[[9.8483906e+00 4.3698579e-01]<br> [8.5892025e-03 7.6991806e+00]], shape=(2, 2), dtype=float32)<br>tf.Tensor(<br>[[23.062654    0.51630944]<br> [ 1.0971084   0.0623657 ]], shape=(2, 2), dtype=float32)<br>‘’’</p>
<h2 id="GradientTape计算梯度"><a href="#GradientTape计算梯度" class="headerlink" title="GradientTape计算梯度"></a>GradientTape计算梯度</h2><p>和numpy的另一个不同是，可以自动跟踪任何变量的梯度。<br>打开一个GradientTape,然后通过tape.watch()来跟踪变量<br>‘’’python<br>a = tf.random.normal(shape=(2,2))<br>b = tf.random.normal(shape=(2,2))<br>with tf.GradientTape() as tape:<br>    tape.watch(a)#开始记录所有有关a参与过的运算<br>    c = tf.sqrt(tf.square(a)+tf.square(b)) #变量a做一些运算</p>
<pre><code>#计算c对于a的梯度
dc_da = tape.gradient(c,a)
print(dc_da)
</code></pre><p>tf.Tensor(<br>[[-0.53557533  0.87920487]<br> [ 0.24663754  0.4680054 ]], shape=(2, 2), dtype=float32)<br>‘’’</p>
<p>对于所有变量，默认状态下会跟踪计算并用来求梯度，所以不用使用tape.watch()<br>‘’’python<br>a = tf.Variable(a)<br>with tf.GradientTape() as tape:<br>    c = tf.sqrt(tf.square(a)+tf.square(b))<br>    dc_da = tape.gradient(c,a)<br>    print(dc_da)</p>
<p>tf.Tensor(<br>[[-0.53557533  0.87920487]<br> [ 0.24663754  0.4680054 ]], shape=(2, 2), dtype=float32)<br>‘’’<br>可以通过多开几个GradientTape来求高阶导数：<br>‘’’python<br>with tf.GradientTape() as outer_tape:<br>    with tf.GradientTape() as tape:<br>        c = tf.sqrt(tf.square(a)+tf.square(b))<br>        dc_da = tape.gradient(c,a)<br>    d2c_d2a = outer_tape.gradient(dc_da,a)<br>    print(d2c_d2a)</p>
<p>tf.Tensor(<br>[[0.54411626 0.33872807]<br> [1.5284648  0.5024241 ]], shape=(2, 2), dtype=float32)<br>‘’’</p>
</tf.tensor:>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

      <div>
       
      </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/01/二分法/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="X">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="X">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/01/01/二分法/" class="post-title-link" itemprop="url">二分法</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2020-01-01 00:12:16 / 修改时间：00:16:14" itemprop="dateCreated datePublished" datetime="2020-01-01T00:12:16+08:00">2020-01-01</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>2019年终记事：一年的经历那么多，回忆起来却短的不可想象。2019年的最后一篇博客，回想第一篇到现在，虽然一路上走走停停，但学习的脚步还在前进。短短二十年放弃的东西比一声叹息多多了，回头看来人生得要有一件能坚持下去的东西……新年的钟声带不走2019的遗憾，希望它能带来2020的希望。</em></p>
<hr>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><blockquote>
<p>在计算机科学中，二分搜索，也称为半间隔搜索，对数搜索，是一种搜索算法，用于查找排序数组中目标值的位置。二分搜索将目标值与数组的中间元素进行比较。<br>如果它们不相等，则消除目标不能位于其中的那一半，并在剩余的一半上继续搜索，再次将中间元素与目标值进行比较，并重复此过程直到找到目标值。<br>如果搜索以其余一半为空结束，则目标不在数组中。<br>在最坏的情况下，二分搜索会以对数时间运行，进行$O(\log_{}n)$比较，其中${n}$是数组中元素的数量，${O}$是Big O表示法， 而${\log}$是对数。 除了小数组以外，二分搜索比线性搜索快。 但是，必须首先对数组进行排序才能应用二进制搜索。有专门为快速搜索而设计的专用数据结构，例如哈希表，可以比二进制搜索更有效地进行搜索。 但是，二分搜索可用于解决更广泛的问题，例如，即使数组中不存在目标，也要在数组中找到相对于目标而言第二小的元素。<br>二进制搜索树和B树数据结构基于二分搜索。<br>——wiki</p>
</blockquote>
<p>在leetcode刷题时我们总能遇到可以利用二分搜索解决的问题，但往往我们写得出来的二分搜索代码并不能work或者潜藏有bug。造成这种现象的原因是纷杂的情况导致算法的细节处理不同而容易忽视边界的细节问题。我们需要一个简洁明了的思路来将问题一般化。矛盾的特殊性应该包含在矛盾的一般性当中，用高度抽象化的过程对具体问题降维打击。</p>
<p>编写博客时翻阅了不少leetcode中的二分题解，在此借鉴并总结一下。在完成的过程中翻阅了《计算机程序设计艺术》的相关章节，受益颇多，一部分内容会穿插在文中讲述。</p>
<h2 id="入题"><a href="#入题" class="headerlink" title="入题"></a>入题</h2><p><strong>一些背景——</strong></p>
<p>《计算机程序设计艺术》的作者 Donald Knuth：</p>
<blockquote>
<p>Although the basic idea of binary search is comparatively straightforward, the details can be surprisingly tricky …</p>
</blockquote>
<p>译：“虽然二分搜索的基本思想很直白，但细节出奇的难以应对…”</p>
<p>他在《计算机程序设计艺术（第三卷）》中也指出了（大意）:也许是第一部出版的关于非数值程序设计方法的书（1946）中，首先提出了二分查找。再到后来的许多人对二分算法的改进直至60年代往后，所有工作才算是基本完成。</p>
<p><strong>一些待解决的问题——</strong></p>
<ol>
<li>中位数索引值的获取</li>
<li>循环执行条件的设置与返回值的选择</li>
<li>分支语句的选择</li>
</ol>
<p><strong>关于模板——</strong></p>
<p>这里借助Thomas H. Cormen在《算法基础—打开算法之门》中的一段伪代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">程序   BINARY-SEARCH(A,n,x)</span><br><span class="line"></span><br><span class="line">输入：</span><br><span class="line">·A：一个数组；</span><br><span class="line">·n：要查找的数组A中元素的个数；</span><br><span class="line">·x：要查找的值；</span><br><span class="line"></span><br><span class="line">输出：要么是满足A[i]=x的索引i，要么是一个特殊值 NOT-FOUND（可取相对数组A的任何无效索引值，例如0或任意负整数）。</span><br><span class="line"></span><br><span class="line">//左右索性记为p,r；中间位置记为q</span><br><span class="line"></span><br><span class="line">1. 将p赋值为1，将r赋值为n。</span><br><span class="line">2. 只要p≤r，执行如下操作：</span><br><span class="line">        A. 将q赋值为⌊(p+r)/2⌋。</span><br><span class="line">        B. 如果A[q]=x，那么返回q。</span><br><span class="line">        C. 否则（A[q]≠x），如果A[q]&gt;x，那么将r赋值为q-1。</span><br><span class="line">        D. 否则（A[q]&lt;x），那么将p赋值为q+1。</span><br><span class="line">3. 返回 NOT-FOUND。</span><br></pre></td></tr></table></figure></p>
<p>这段算法描述是我们常规的理解和处理方法，这次打算讨论的是在它的基础上进行一定的改变，并简单谈谈优劣。</p>
<p><strong>基本思想——</strong></p>
<p>二分的基本思想其实就是每次可以将当前的数中将近一般的不满足要求的数全部除掉，所以大O时间复杂度是$O(\log_{2}n)$,可以达到对数级的复杂度。</p>
<p>为了真正了解二分搜索算法中所发生的事情，最好把它想象成一棵二叉搜索树。</p>
<p>关于平均比较次数暂且不论。</p>
<h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><p><strong>1. 中位数索引值</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> mid=(left+right)/<span class="number">2</span>;</span><br></pre></td></tr></table></figure>
<p>上面的代码是我们经常写的，但它确实存在有bug，在于当left与right都很大的时候，left+right很有可能超过int类型能表示的最大值（32位机下为$2^{31}-1$，即2147483647），此时会产生整形溢出产生负值，为了避免此问题的发生一般会写作下面的形式：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> mid=left+(right-left)/<span class="number">2</span>;</span><br></pre></td></tr></table></figure></p>
<p>可以有效避免绝大多数会产生溢出的情况。但它并不是最完美的写法。我们知道对于二进制计算机来说，除法的计算并不容易完成，二进制的位运算应该是最简单快捷的。当面对需要以二作为除数的时候，选择&gt;&gt;1，会带来更好的效果。但仅仅只是修改这一点，mid的计算仍旧存在冗余的部分。</p>
<p>我们从原码的角度思考，其实不难发现，因为第一位用来表示正负符号的缘故，当发4个字节下可以表示的最大正整数比int最大值两倍还多。当发生整形溢出时，实际存储的二进制只不过因为最高位从0变为1，导致整形正数被认为是整形负数，无法正确表示我们目标的数值，但其实内部存储的数据如果按无符号整形（即最高位具有二进制权值，而非表示符号）来输出其实是我们需要的值，此时再对这个数进行<font color="#FF0000">无符号的&gt;&gt;1</font>操作得到我们需要的除二结果。</p>
<p>关于无符号右移，在java中使用&gt;&gt;&gt;，所以java代码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> mid = (right + left) &gt;&gt;&gt; <span class="number">1</span> ;</span><br></pre></td></tr></table></figure></p>
<p>而在c语言中，仅有的&gt;&gt;运算符却是在有符号位时产生的是有符号的右移，所以运算前需要将运算数值强制类型转换为无符号型，再右移。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> mid=((<span class="keyword">unsigned</span> <span class="keyword">int</span>)(left+right))&gt;&gt;<span class="number">1</span>;</span><br></pre></td></tr></table></figure></p>
<p>不进行强制类型转换的话，会把溢出产生的负数值除二。具体大家看下面的例子：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a=<span class="number">2147483647</span>,b=<span class="number">2147483645</span>;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"%d"</span>,(a+b)&gt;&gt;<span class="number">1</span>);<span class="comment">//结果输出-2</span></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"%u"</span>,((<span class="keyword">unsigned</span> <span class="keyword">int</span>)(a+b))&gt;&gt;<span class="number">1</span>);<span class="comment">//结果输出2147483646</span></span><br></pre></td></tr></table></figure></p>
<p><strong>2. 算法设计</strong></p>
<p>这里将之前提出的关于“循环执行条件的设置与返回值的选择”以及“分支选择”问题归结在一起，我们其实是从算法设计的角度来考虑的。</p>
<p>首先如上面的伪代码，我们循环的条件设置的为left≤right，出循环时的情况是left已经越过right，表示全部的元素都被搜索完。我们的修改是将循环条件改为left &lt; right,此时出循环的情况为left与right相等，表示整个数组只有现在唯一一个元素没有被搜索，也就是下标为left（right）的元素。根据不同的情形，对最后一个元素进行判断。比如说，我们知道这个数组一定会有我们搜索的值时，此时不用判断就可以知道当其他元素都被排除时，最后这个就是我们要找的元素。如果我们不确定是否一定存在，那么在循环外部额外判断此时最后的元素是否满足条件即可。</p>
<p>问题的关键在于这样的设计意义是什么，因为当我们用之前的方法，我们在每一次都需要判断是否中值是我们需要的值，但是根据统计规律要查找的数据一般情况下出现在中间的情况并不多。而且出循环时表示没有找到，举个例子：某些情况下我们会想把没有找到的元素添加进我们所查找的表中时，我们想先返回插入的位置，此时我们需要考虑返回left或者right。而每次遇到不同的问题我们需要返回的值都需要根据不同的情况选择，这样的设计并不完美。我们对于任意情况下都可以统一处理是理想状态，这样这段代码的复用性也会变高。</p>
<p>关于死循环，死循环容易发生在只有 2 个元素时，我需要慎重选择中位数，一定要确保：</p>
<ol>
<li>如果分支的逻辑，在选择左边界的时候，不能排除中位数，那么中位数就选“右中位数”，只有这样区间才会收缩，否则进入死循环。</li>
<li>同理，如果分支的逻辑，在选择右边界的时候，不能排除中位数，那么中位数就选“左中位数”，只有这样区间才会收缩，否则进入死循环。</li>
</ol>
<p>在区间中的元素只剩下 2 个时候，例如：left = 3，right = 4。此时左中位数就是左边界，如果你的逻辑执行到 left = mid 这个分支，且你选择的中位数是左中位数，此时左边界就不会得到更新，区间就不会再收缩（理解这句话是关键），从而进入死循环；<br>为了避免出现死循环，你需要选择中位数是右中位数，当逻辑执行到 left = mid 这个分支的时候，因为你选择了右中位数，让逻辑可以转而执行到 right = mid - 1 让区间收缩，最终成为 1 个数，退出 while 循环。</p>
<h1 id="总结与延申"><a href="#总结与延申" class="headerlink" title="总结与延申"></a>总结与延申</h1><p>其实Donald Knuth在著作中也指出了</p>
<blockquote>
<p>H.Bottenbruch迈出了二分算法的第二步，介绍了有趣的变形，避免了在最后结束之前单作一次相等判断：在步骤B2中利用$i⬅⌈(l+u)/2⌉$代替$⌊(l+u)/2⌋$，每当 $K≥K_i$时置$l⬅i$；然后在每一步中$u-l$都减值。最后，当$l=u$时，我们有$K_l≤K≤K_{l+1}$，而且再做一次比较即可判断这个查找是否成功（假定开始时$K≥K_l$）。这个思想子啊许多计算机上稍微加速了内循环，而且同样的原理可以在这一节讨论的所有算法使用，但由于此前推导出的一次成功的平均查找次数于一次不成功的平均查找次数之间的关系一次成功的查找平均将要求大约再做一次迭代。由于内循环仅执行$lgN$次，因此在这一次额外的迭代与一次更快的循环之间的折衷并不节省时间，除非N非常大。在含有重复码值时，获取该算法给定码值最右出现，这一性质有时很重要。<br><em>大师的思想与见识比我们深远的多，多多读书无疑是一场对于世界和自我的再发掘。</em></p>
</blockquote>
<p>在上述描述中，我们不难看出来其实整个算法的核心就是在靠左右边界夹逼，而我们做出的改变其实再更深刻的讨论中，在不涉及大数量的情况下，对时间的影响并不明显。但是这种算法仍然有可用性，就如我在之前分析的一样。</p>
<p>最后的一点延申，我们的二分使用了left mid right三个指针，而仅使用如下两个量，记录当前位置i,和它的变化速度δ；每次不相等的比较之后，我们可以置i⬅1±δ和δ⬅δ/2（近似地）。这是可以的，但要对细节极端小心才行，简化的解决方法注定引起失误！这个算法实现后，产生的一颗“均匀的”二分查找树，我们可以观察它得到更好的算法。</p>
<p>而且另外一点我们在整个过程的观察中，其实可以发现斐波那契数列可以起到和2的乘方相似的作用。斐波那契搜索就是在二分查找的基础上根据斐波那契数列进行分割的。在斐波那契数列找一个等于略大于查找表中元素个数的数F[n]，将原查找表扩展为长度为F[n]<br>(如果要补充元素，则补充重复最后一个元素，直到满足F[n]个元素)，完成后进行斐波那契分割，即F[n]个元素分割为前半部分F[n-1]个元素，后半部分F[n-2]个元素，找出要查找的元素在那一部分并递归，直到找到。斐波那契查找，是区间中单峰函数的搜索技术。乍看之下，似乎有些神秘，就如Donald Knuth所说，如果我们简单地把程序拿出来并试图看看它在干什么活，它似乎在变魔术，但只要把查找树画出来，神秘感就消失了。<br>这次地介绍就到此结束了。</p>
<p><em><font color="#FF0000" size="0">关于平均比较数和均匀二分查找等详细内容，本文暂时未涉及，后续可能补充，有兴趣的读者可以自行了解。</font></em></p>
<hr>
<p align="right"><font face="Segoe Script">Attempt the end;and never stand to doubt;<br>
Nothing's so hard,but search will find it out.</font></p>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

      <div>
       
      </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/02/Excel模块简析/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="X">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="X">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/02/Excel模块简析/" class="post-title-link" itemprop="url">Excel模块简析</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-02 17:30:47" itemprop="dateCreated datePublished" datetime="2019-06-02T17:30:47+08:00">2019-06-02</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-08-07 15:08:09" itemprop="dateModified" datetime="2019-08-07T15:08:09+08:00">2019-08-07</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <hr>
<p>Python中处理Excel文件主要依靠xlrd xlwt和pandas库的模块进行数据处理。这里主要介绍xlrd和xlwt扩展包。</p>
<hr>
<p>xlrd 是一个库, 用于读取 Excel 文件中的数据和格式信息, 无论它们是. xls 还是. xlsx 文件。<br>对于包含文本的数据处理我们需要注意的是扩展包所支持的编码方案，此包将所有文本字符串显示为 Python unicode 对象。<br>我们通常会接触到的Exel文件中日期的存储方式与一般数据有格式上的区别。但是在Excel文件中，日期不存储为单独的数据类型;它们存储为浮点数。这个浮点数代表从1990年1月0日，或者说1899年12月31日开始经过的日期数加上一个24小时的小数部分。（注：在Mac上日期是从1994年1月1日开始）这对我们处理这些数据产生了预期之外的困难，原因在于我们不容易分辨一个浮点数是否表示日期数据。对于本模块，它通过检查已应用于每个数字单元格的格式来帮助我们，它可以检测到单元格数据的格式，从而判定单元格中的值是否是日期。但我们处理这些数据时，仍要格式化进行。往往我们的处理方式如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> worksheet.cell_type(row_index, col_index) == <span class="number">3</span>:</span><br><span class="line"></span><br><span class="line">	date_cell = xldate_as_tuple(worksheet.cell_value(row_index,col_index),workbook.datemode)</span><br><span class="line">		date_cell = date(*date_cell[<span class="number">0</span>:<span class="number">3</span>]).strftime(<span class="string">'%m/%d/%Y'</span>)</span><br></pre></td></tr></table></figure></p>
<p>简单解释一下，在xlrd的文档中我们可以知道，日期型数据的单元格类型为3。这里使用了worksheet对象的cell_value函数和行列索引来获得单元格中的值。这个值作为xldate_as_tuple()函数的第一个参数，参数workbook.datemode，可以使函数确定日期是基于1990年还是1994年，返回一个元组。strftime将data对象转化为格式化字符串。<br>基础部分我就直接列在下方：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xlrd.open_workbook(filename=<span class="keyword">None</span>, logfile=&lt;_io.TextIOWrapper name=<span class="string">'&lt;stdout&gt;'</span> mode=<span class="string">'w'</span> encoding=<span class="string">'UTF-8'</span>&gt;, verbosity=<span class="number">0</span>, use_mmap=<span class="number">1</span>, file_contents=<span class="keyword">None</span>, encoding_override=<span class="keyword">None</span>, formatting_info=<span class="keyword">False</span>, on_demand=<span class="keyword">False</span>, ragged_rows=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></p>
<p><em>filename– 要打开的电子表格文件的路径。
</em>logfile – 一个打开的文件, 将消息和诊断写入其中。<br><em>verbosity – 增加写入日志文件的跟踪材料的数量。
</em>use_mmap – 是否使用 mmap 模块是试探性确定的。使用此参数覆盖结果。<br>目前的试探: mmap (如果存在) 将使用它。<br>file_contents – 一个字符串或者一个mmap.mmap对象或者其他类似行为的对象。 如果file_contents提供, filename将不会被使用, except (possibly)但 (可能) 在消息中除外。<br>encoding_override – 用于克服旧版本文件中丢失或错误的代码页信息。<br>formatting_info –默认值为False, 它节省内存。 在这种情况下, “空白” 单元格 (具有自己的格式信息但没有数据) 通过忽略文件的BLANK和MULBLANK记录被视为空。 这将切断空单元格或空白单元格行的任何底部或右侧 “边距”。<br>当为True,格式信息将从电子表格文件中读取。这将提供所有单元格, 包括空单元格和空白单元格。格式信息可用于每个单元格。<br>请注意, 当与 xlsx 文件一起使用时，这将引发注意实现错误,。<br>on_demand –控制工作表最初是否全部加载, 或者在调用方要求时加载。<br>ragged_rows –<br>默认值False表示所有行都用空单元格填充, 以便所有行的大小与 ncols中的大小相同。<br>True表示行的末尾没有空单元格。如果行的大小千差万别, 这可能会节省大量内存。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

      <div>
       
      </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/05/26/sqlite3-SQLite数据库模块简单认识/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="X">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="X">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/26/sqlite3-SQLite数据库模块简单认识/" class="post-title-link" itemprop="url">sqlite3-SQLite数据库模块简单认识</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-26 19:35:07" itemprop="dateCreated datePublished" datetime="2019-05-26T19:35:07+08:00">2019-05-26</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-08-07 15:08:47" itemprop="dateModified" datetime="2019-08-07T15:08:47+08:00">2019-08-07</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong><em>SQLite 是一个C语言库，它可以提供一种轻量级的基于磁盘的数据库，这种数据库不需要独立的服务器进程，也允许需要使用一种非标准的 SQL 查询语言来访问它。一些应用程序可以使用 SQLite 作为内部数据存储。可以用它来创建一个应用程序原型，然后再迁移到更大的数据库，比如 PostgreSQL 或 Oracle。</em></strong><br>要使用这个模块，必须先创建一个 Connection 对象，它代表数据库。下面例子中，数据将存储在 example.db 文件中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import sqlite3</span><br><span class="line">conn = sqlite3.connect(&apos;example.db&apos;)</span><br></pre></td></tr></table></figure></p>
<p>你也可以使用 :memory: 来创建一个内存中的数据库</p>
<p>当有了 Connection 对象后，你可以创建一个 Cursor 游标对象，然后调用它的 execute() 方法来执行 SQL 语句：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">c = conn.cursor()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建表</span></span><br><span class="line">c.execute(<span class="string">'''CREATE TABLE stocks</span></span><br><span class="line"><span class="string">             (date text, trans text, symbol text, qty real, price real)'''</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 插入一行数据</span></span><br><span class="line">c.execute(<span class="string">"INSERT INTO stocks VALUES ('2006-01-05','BUY','RHAT',100,35.14)"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存（提交）更改</span></span><br><span class="line">conn.commit()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们也可以在完成任务后，关闭连接</span></span><br><span class="line"><span class="comment"># 只需要保证在关闭之前任何更改都已提交</span></span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure></p>
<p>这些数据被持久化保存了，而且可以在之后的会话中使用它们：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line">conn = sqlite3.connect(<span class="string">'example.db'</span>)</span><br><span class="line">c = conn.cursor()</span><br></pre></td></tr></table></figure></p>
<p>通常你的 SQL 操作需要使用一些 Python 变量的值。你不应该使用 Python 的字符串操作来创建你的查询语句，因为那样做不安全；它会使你的程序容易受到 SQL 注入攻击（在 <a href="https://xkcd.com/327/" target="_blank" rel="noopener">https://xkcd.com/327/</a> 上有一个搞笑的例子，看看有什么后果）</p>
<p>推荐另外一种方法：使用 DB-API 的参数替换。在你的 SQL 语句中，使用 ? 占位符来代替值，然后把对应的值组成的元组做为 execute() 方法的第二个参数。（其他数据库可能会使用不同的占位符，比如 %s 或者 :1）例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># Never do this -- insecure!</span><br><span class="line">symbol = &apos;RHAT&apos;</span><br><span class="line">c.execute(&quot;SELECT * FROM stocks WHERE symbol = &apos;%s&apos;&quot; % symbol)</span><br><span class="line"></span><br><span class="line"># Do this instead</span><br><span class="line">t = (&apos;RHAT&apos;,)</span><br><span class="line">c.execute(&apos;SELECT * FROM stocks WHERE symbol=?&apos;, t)</span><br><span class="line">print(c.fetchone())</span><br><span class="line"></span><br><span class="line"># Larger example that inserts many records at a time</span><br><span class="line">purchases = [(&apos;2006-03-28&apos;, &apos;BUY&apos;, &apos;IBM&apos;, 1000, 45.00),</span><br><span class="line">             (&apos;2006-04-05&apos;, &apos;BUY&apos;, &apos;MSFT&apos;, 1000, 72.00),</span><br><span class="line">             (&apos;2006-04-06&apos;, &apos;SELL&apos;, &apos;IBM&apos;, 500, 53.00),</span><br><span class="line">            ]</span><br><span class="line">c.executemany(&apos;INSERT INTO stocks VALUES (?,?,?,?,?)&apos;, purchases)</span><br></pre></td></tr></table></figure></p>
<p>要在执行 SELECT 语句后获取数据，你可以把游标作为 iterator，然后调用它的 fetchone() 方法来获取一条匹配的行，也可以调用 fetchall() 来得到包含多个匹配行的列表。</p>
<p>下面是一个使用迭代器形式的例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; for row in c.execute(&apos;SELECT * FROM stocks ORDER BY price&apos;):</span><br><span class="line">        print(row)</span><br><span class="line"></span><br><span class="line">(&apos;2006-01-05&apos;, &apos;BUY&apos;, &apos;RHAT&apos;, 100, 35.14)</span><br><span class="line">(&apos;2006-03-28&apos;, &apos;BUY&apos;, &apos;IBM&apos;, 1000, 45.0)</span><br><span class="line">(&apos;2006-04-06&apos;, &apos;SELL&apos;, &apos;IBM&apos;, 500, 53.0)</span><br><span class="line">(&apos;2006-04-05&apos;, &apos;BUY&apos;, &apos;MSFT&apos;, 1000, 72.0)</span><br></pre></td></tr></table></figure></p>
<hr>
<p>摘自Python官方文档</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

      <div>
       
      </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/05/19/浮点的限制与争议/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="X">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="X">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/19/浮点的限制与争议/" class="post-title-link" itemprop="url">浮点的限制与争议</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-19 12:22:38 / 修改时间：13:21:25" itemprop="dateCreated datePublished" datetime="2019-05-19T12:22:38+08:00">2019-05-19</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>浮点算术在计算机领域的广泛应用不必多说。应该大多数人都有这样的经历，总是在不经意间会遇到浮点运算的一些不满足预期的奇怪输出。这里主要来探讨一下个中奥秘。<br>首先，我们都明白，大多数十进制小数都不能精确地表示为二进制小数，这导致在大多数情况下，你输入的十进制浮点数都只能近似地以二进制浮点数形式储存在计算机中。用十进制来理解这个问题显得更加容易一些。考虑分数$1/3$。我们可以得到它在十进制下的一个近似值$0.3$，或者更接近$0.33$，或者更接近的$0.333……$无论你写下多少，永远只能更接近。同样，我们用$2$作为基数，$0.1$是永远也无法精确表示为二进制的小数。在二进制下，$1/10$是一个无限循环小数$0.0001100110011001100110011001100110011001100110011…$在任何一个位置停下都仅仅只是近似值。因此，在今天的大部分架构上，浮点数都只能近似地使用二进制小数表示，对应分数的分子使用每8字节的前53位表示，分母则表示为$2$的幂次(IEEE754)。在$1/10$这个例子中，相应的二进制分数是 $3602879701896397/2^{55}$ ，它很接近$1/10$，但并不是$1/10$。往往我们能观察到的输出结果精度达不到近似值有差异的地方。记住了，即使输出的结果看起来好像就是$1/10$的精确值，实际储存的值只是最接近$1/10$的计算机可表示的二进制分数。有趣的是，有许多不同的十进制数共享相同的最接近的近似二进制小数。例如，$0.1$、$0.10000000000000001$、$0.1000000000000000055511151231257827021181583404541015625$全都近似于$3602879701896397/2^{55}$。由于所有这些十进制值都具有相同的近似值，因此可以显示其中任何一个。<br>出现浮点运算不符合预期值的情况，其本质不是语言的限制，也不是代码的问题，你在所有支持在硬件中浮点运算的语言都会发现相同的情况。<br>有时我们想要更美观的输出，我们可以对小数进行格式化输出，但其实这并不影响浮点数在计算机里的存储值，只是见舍入后的结果进行显示而已。我们用Python举例。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; format(math.pi,&apos;.12g&apos;)</span><br><span class="line">&apos;3.14159265359&apos;</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; format(math.pi,&apos;.2f&apos;)</span><br><span class="line">&apos;3.14&apos;</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; format(math.pi)</span><br><span class="line">&apos;3.141592653589793&apos;</span><br></pre></td></tr></table></figure></p>
<p>我们看到的输出结果只是表象而已，不理解内部的运算会在应用过程中产生很多问题。比如下面的例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; .1+.1+.1==.3</span><br><span class="line">Flase</span><br></pre></td></tr></table></figure></p>
<p>我们无法将$2$为基数的$0.1$精确到十进制的$1/10$，对应的$0.3$同样无法精确。哪怕我们使用Python的$round()$函数预先舍入也无济于事。不过预后舍入就可以达到我们想要的效果。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; round(.1,1)+round(.1,1)+round(.1,1)==round(.3,1)</span><br><span class="line">False</span><br><span class="line">&gt;&gt;&gt;round(.1+.1+.1,10)==round(.3,10)</span><br><span class="line">True</span><br></pre></td></tr></table></figure></p>
<p>浮点数运算会造成许多这样的“意外”。不过大多数情况下一点误差是可以容忍的。需要注意的是，每次浮点运算都可能导致新的舍入错误。<br>对于需要精确十进制表示的使用场景，请尝试使用$decimal$模块，该模块实现了适合会计应用和高精度应用的十进制运算。<br>另一种形式的精确运算由$fractions$模块提供支持，该模块实现了基于有理数的算术运算（因此可以精确表示像$1/3$这样的数值）。<br>如果你是浮点运算的重度用户，你应该看一下数值运算Python包NumPy以及由SciPy项目所提供的许多其它数学和统计运算包。参见<a href="https://scipy.org" target="_blank" rel="noopener">https://scipy.org</a>。<br>Python也提供了一些工具，可以在你真的想要知道一个浮点数精确值的少数情况下提供帮助。例如float.as_integer_ratio()方法会将浮点数表示为一个分数:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x=3.14159</span><br><span class="line">&gt;&gt;&gt; x.as_integer_ratio()</span><br><span class="line">(3537115888337719, 1125899906842624)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x==3537115888337719/1125899906842624</span><br><span class="line">True</span><br></pre></td></tr></table></figure></p>
<p>这样的表示法是精确的，可以跨版本移植，和别的标准相同的语言（Java、C99）交换数据。</p>
<hr>
<p>这里引出问题所在和基本的解决措施。下一篇将深入本质探讨此问题，包括IEEE754的相关具体细节。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

      <div>
       
      </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/05/10/算法题：爬楼梯/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="X">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="X">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/10/算法题：爬楼梯/" class="post-title-link" itemprop="url">算法题：爬楼梯</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-10 02:29:07" itemprop="dateCreated datePublished" datetime="2019-05-10T02:29:07+08:00">2019-05-10</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-08-07 18:00:04" itemprop="dateModified" datetime="2019-08-07T18:00:04+08:00">2019-08-07</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong><em>题目：假设你正在爬楼梯，需要n阶你才能到达楼顶。每次你可以爬1阶或2阶台阶。你有多少种不同的方法可以爬到楼顶呢？</em></strong></p>
<hr>
<p>这里将对此问题写出多个解法，包括一般容易实现的递归，以及它的一步一步优化。</p>
<hr>
<h2 id="贪心算法"><a href="#贪心算法" class="headerlink" title="贪心算法"></a>贪心算法</h2><p>这是我看到题目后最先想到的也是十分麻烦的方法，但我觉得有必要拿出来看看。思路是，如果爬楼梯每次都选择同一种，即要么全走两阶大致（n的奇偶决定，暂且定为偶数便于理解）一共n/2次到达楼顶，要么全走一阶一共n次就可以到达楼顶。选取其中一种状况进行分析即可，这两种都是终极状态，我需要做的是对两者的相互演化过程做出模拟即可。<br>举个例子，这里优先考虑把选择次数降到最低，每次均走2阶。然后把一个两阶拆成两个1阶，每次拆分选择次数就增加1，再对这一共n/2+1次选择进行排列组合得到一定的方法数，即绝大多数都是走2阶，选择一下在哪几次走一阶，不同的选择是不同的方法。然后再将一个两阶拆分，继续上述操作，直至把所有两阶全部拆分为1阶。这时统计所有方法数即可。这里的代码是上述例子的实现，因为涉及到排列组合，组合数用阶乘计算方便直接，所以又定义了两个子函数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">int PermuteCombine(int WayNum,int StairsNum)//全部先尽可能多的转化为一次2个台阶的方法，，再将一次2个台阶拆解为两个一次台阶，在在总次数中排列组合。 </span><br><span class="line">&#123;</span><br><span class="line">	int i;</span><br><span class="line">	if(StairsNum%2==0)//总阶数进行奇偶判断 ，处理大同小异，均从顶向下、以迭代的方法将问题 扩大为一个规模稍大的问题 </span><br><span class="line">		for(i=0;i&lt;=StairsNum/2;i++)</span><br><span class="line">			WayNum+=C(StairsNum/2+i,StairsNum/2-i);</span><br><span class="line">	else</span><br><span class="line">		for(i=0;i&lt;(StairsNum+1)/2;i++)</span><br><span class="line">			WayNum+=C((StairsNum+1)/2+i,(StairsNum-1)/2-i); </span><br><span class="line">	return WayNum;</span><br><span class="line">&#125;</span><br><span class="line">int factorial(int n)//阶乘函数 n！ </span><br><span class="line">&#123;</span><br><span class="line">	if(n==1)	return 1;//递归出口 </span><br><span class="line">	return n*factorial(n-1);</span><br><span class="line">&#125;</span><br><span class="line">int C(int n,int m)//利用数学定义计算组合数 ,n个不同元素中取出m个元素的组合数。用符号 C(n,m) 表示</span><br><span class="line">&#123;</span><br><span class="line">	if(m==0||n==m)//特殊情况处理 </span><br><span class="line">		return 1;</span><br><span class="line">	else</span><br><span class="line">		return (factorial(n)/(factorial(n-m)*factorial(m)));//计算公式C(n,m)=n!/[m!*(n-m)!]将结果返回 </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>不难看出，这里的处理其实是不断地将问题规模扩大，而如果先假定全走1阶，则整个程序体现出来，应该是越来越多的两个一组的1阶被一个二阶取代，问题规模不断变小。其实本质是一样的。</p>
<blockquote>
<p>贪心算法（英语：greedy algorithm），又称贪婪算法，是一种在每一步选择中都采取在当前状态下最好或最优（即最有利）的选择，从而希望导致结果是最好或最优的算法。不从整体最优上加以考虑，它所做出的是在某种意义上的局部最优解。</p>
</blockquote>
<p>这里的方法其实也不是特别符合贪婪的定义，但从某种处理方式上来看具有一定的相似性。贪心算法简单来说两个基本要素，一是贪心选择，而是最优子结构。每做一次贪心选择就将所求问题简化为一个规模更小的子问题。先全走1阶，后一步一步合并成2阶，就是这样一个过程。当一个问题的最优解包含其子问题的最优解时，称此问题具有最优子结构性质。这里与动态规划十分接近，可以推测此题应该也会有动态规划的解法。<br>    至于贪心的局限在于它在达成整体最优的路上是不可回退的。即在当前选择时，是无法返回上一次选择的状态。</p>
<h2 id="树形递归模拟爬楼梯"><a href="#树形递归模拟爬楼梯" class="headerlink" title="树形递归模拟爬楼梯"></a>树形递归模拟爬楼梯</h2><p>上一个算法不得不说写的是又烂又长，看的让人头大。这里要介绍的方法理解起来倒是简单多了。看到小标题，相信大家心里已经知道是什么样的了，不多说了，上代码。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">int recursion(int NowNum,int StairsNum)//从0阶台阶开始模拟爬楼梯，构建一个递归树 ，每一层都有两个分支选择，+1或+2。 </span><br><span class="line">&#123;						//两个递归出口 </span><br><span class="line">	if(NowNum&gt;StairsNum)//上一阶加2后超出总阶数 则此方法无效不计数 </span><br><span class="line">		return 0;</span><br><span class="line">	if(NowNum==StairsNum)//刚好满足总阶数   则此方法（在递归树中的分支路径）有效记一次 </span><br><span class="line">		return 1;</span><br><span class="line">	return recursion(NowNum+1,StairsNum)+recursion(NowNum+2,StairsNum);// 将当前方法（路径）继续深化到下一层，直到返回 。上一层方法是下层方法的总和，每层都有两个分支。 </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>树形递归，时间复杂度$O(2^n)$，空间树大小$2^n$。</p>
<h2 id="记忆化递归"><a href="#记忆化递归" class="headerlink" title="记忆化递归"></a>记忆化递归</h2><p>上一个方法倒是简单易懂，但不可避免的浪费了许多空间和时间。其实如果你仔细画过或者模拟过上面的递归树，不难发现一件事，我们有很多重复计算。没有模拟过也不要紧，我们现在大致演示一下。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">                   0</span><br><span class="line">	  _________|__________</span><br><span class="line">	 |                    |</span><br><span class="line">	 1 		      2</span><br><span class="line">    _____|_____          _____|_____</span><br><span class="line">   |           |        |           |</span><br><span class="line">   2           3        3           4</span><br><span class="line"> __|__       __|__    __|__       __|__</span><br><span class="line">|     |     |     |  |     |     |     |</span><br><span class="line">3     4     4     5  4     5     5     6</span><br><span class="line">......</span><br></pre></td></tr></table></figure></p>
<p>仔细观察会发现在这个树中，有许多相似的结构分支，尤其是从零开始的分支2，直接包含在分支1中，也就是说，我们深度优先遍历递归树的时候，其实有多于一半的时间和大量空间的浪费都是不必要的。我们只需要用一个数组记录每次的值，当需要递归去计算某个分支时，如果已经计算过则直接从数组中获取值即可，不必再次遍历子树。代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">//在主函数中要先定义记忆数组，并初始化零。</span><br><span class="line">int memo[StairsNum+1],i;</span><br><span class="line">for(i=0;i&lt;StairsNum+1;i++)//变量定义数组长度后无法直接初始化，定义完后用循环初始化数组。 </span><br><span class="line">	memo[i]=0;</span><br><span class="line"></span><br><span class="line">int MemoRecur(int NowNum,int StairsNum,int memo[])// 之前的递归过程有大量的重复计算，改进后把每一步结果都储存下来，以便需要的时候直接使用就不用再次进入递归计算，减少时间，定义数组会占用n大小的空间 </span><br><span class="line">&#123;</span><br><span class="line">	if(NowNum&gt;StairsNum)</span><br><span class="line">		return 0;</span><br><span class="line">	if(NowNum==StairsNum)</span><br><span class="line">		return 1;</span><br><span class="line">	if(memo[NowNum]&gt;0)</span><br><span class="line">		return memo[NowNum];</span><br><span class="line">	memo[NowNum]=MemoRecur(NowNum+1,StairsNum,memo)+MemoRecur(NowNum+2,StairsNum,memo);</span><br><span class="line">	return memo[NowNum]; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>典型的浪费空间换取时间的策略。毫无疑问我们将上一次的算法进行了优化。</p>
<h2 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h2><p>之前的猜测可以证实了，这里确实可以用动态规划，尤其是在上一个优化中，我们发现记忆数组其实帮我完成了一件事——抽象描述就是：使得我们可以在选择时回退到之前选择过的情形而直接获取答案。至于这里使用动态规划的考虑是这样的：如第i阶可由(i-1)阶爬1阶或(i-2)阶爬两阶得到，规划到最初，第三阶由第二阶爬1阶或第1阶爬两阶得到，第四阶是三阶爬1或2阶爬2…类推 。代码如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">int DynamicProgram(int StairsNum)</span><br><span class="line">&#123;</span><br><span class="line">	int dp[StairsNum+1],i;</span><br><span class="line">	dp[1]=1,dp[2]=2;</span><br><span class="line">	for(i=3;i&lt;StairsNum+1;i++)</span><br><span class="line">		dp[i]=dp[i-1]+dp[i-2];</span><br><span class="line">	return dp[StairsNum];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>一层循环就结束整个问题，相应，降低了时间，但是用了数组就浪费了空间。</p>
<h2 id="斐波那契数列"><a href="#斐波那契数列" class="headerlink" title="斐波那契数列"></a>斐波那契数列</h2><p>其实大家应该在之前的某种方法就已经的发现，这道题在数学上就是求斐波那契数列的第N项的值。那么如何求这个数列就变得重要了。也许有人会用递归算，这不免和之前的我们优化过的算法陷入同样的情况，子树会重复，再一步一步优化就到了用一遍循环就算出值。其实对这个数列有所了解的同学应该知道，这个数列是有通项公式的。如下<br>$a_n=\frac{1}{\sqrt 5}[(\frac{1+\sqrt 5}{2})^n-(\frac{1-\sqrt 5}{2})^n]$<br>我们将值代入即可求出对于的通项值，代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int Fib(int StairsNum)//直接使用公式,空间O(1),由于使用POW函数，时间变为O(log n) </span><br><span class="line">&#123;</span><br><span class="line">	double s5=sqrt(5);</span><br><span class="line">	return	(int)(1/s5*(pow((1+s5)/2,StairsNum+1)-pow((1-s5)/2,StairsNum+1)));//可能由于计算精度问题，极少部分答案与准确值相差1， </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>由于计算次方我们调用了pow()函数，需要导入math.h，无形中我们在计算公式时，还是会消耗一定时间。这时我们的空间复杂度$O(1)$，调用函数缘故，时间复杂度：$O(\log_{}n)$</p>
<h2 id="矩阵快速幂"><a href="#矩阵快速幂" class="headerlink" title="矩阵快速幂"></a>矩阵快速幂</h2><p>借助公式的方法其实不是那么完美，因为有时会有情况限制我们对于函数的使用，那有没有类似的方法可以快速计算出斐波那契数列呢？这里介绍矩阵快速幂。要能使用这方法，我们需要先知道如何用矩阵表示斐波那契数列。<br>我们引入矩阵乘法进行推导：<br>$\left[<br> \begin{matrix}<br>   F_n\\<br>   F_{n-1}<br>  \end{matrix}<br>\right]=<br>\left[<br> \begin{matrix}<br>   F_n+F_{n-2}\\<br>   F_{n-1}<br>  \end{matrix}<br>\right]=<br>\left[<br> \begin{matrix}<br>   1&amp;1\\<br>   1&amp;0<br>  \end{matrix}<br>\right]\cdot<br>\left[<br> \begin{matrix}<br>   F_{n-1}\\<br>   F_{n-2}<br>  \end{matrix}<br>\right]$<br>然后化简：<br>$\left[<br> \begin{matrix}<br>   F_n\\<br>   F_{n-1}<br>  \end{matrix}<br>\right]=<br>\left[<br> \begin{matrix}<br>   1&amp;1\\<br>   1&amp;0<br>  \end{matrix}<br>\right]^{n-1}\cdot<br>\left[<br> \begin{matrix}<br>   1\\<br>   0<br>  \end{matrix}<br>\right]$<br>此时我们知道，想要得出含有斐波那契数列的矩阵，只需要对一个矩阵求幂即可，那么如何能快速求出高次幂变成我们关注的重点。<br>首先由整数快速幂引入。当我们想求$x^8$时，我不必将x自乘8次，而是可以转化为求$x^2$三次，主要是这种结合思想。那用怎样的策略才能把高次拆分成计算最快的低次乘积？我们用$x^{25}$举例子。<br>25的二进制是11001,则$x^{25}=x^{16}\cdot x^8\cdot x^1$，具体代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">int QuickPow(int x,int N)</span><br><span class="line">&#123;</span><br><span class="line">    int res = x;</span><br><span class="line">    int ans = 1;</span><br><span class="line">    while(N)</span><br><span class="line">    &#123;</span><br><span class="line">        if(N&amp;1)//位与运算判断N最后一位是否为1</span><br><span class="line">        &#123;</span><br><span class="line">            ans = ans * res;</span><br><span class="line">        &#125;</span><br><span class="line">        res = res*res;</span><br><span class="line">        N = N&gt;&gt;1;//位右移，判断下一位</span><br><span class="line">    &#125;</span><br><span class="line">    return ans;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看出res与二进制位权值对应，而ans则负责将我们二进制位上存在1 的进行记录。当N=25时，最终res变成了$x^{32}$，ans变成了$x^{25}$。简单来说就是res一直跑，当遇到我们需要的ans时，在前一次的ans上再乘当前的res。快速幂的处理方法就是这样，这种情形下，我们只使用常量级空间$O(1)$，时间复杂度到了与使用函数一样的$O(\log_{}n)$。我们现在只需要把这种方法放到矩阵中去即可。代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">int QuickPower(int N)</span><br><span class="line">&#123;</span><br><span class="line">	int n=2,i,j;</span><br><span class="line">	N-=1;//</span><br><span class="line">	int ans[2][2],res[2][2],tep[2][2];</span><br><span class="line">	for(i=0;i&lt;n;i++)</span><br><span class="line">		for(j=0;j&lt;n;j++)//初始化ans矩阵，变成单位矩阵E，进行矩阵乘法的基石 </span><br><span class="line">		&#123;</span><br><span class="line">			if(i==j)</span><br><span class="line">				ans[i][j]=1;</span><br><span class="line">			else</span><br><span class="line">				ans[i][j]=0;</span><br><span class="line">		&#125;</span><br><span class="line">	for(i=0;i&lt;n;i++)//初始化res矩阵 </span><br><span class="line">		for(j=0;j&lt;n;j++)</span><br><span class="line">		&#123;</span><br><span class="line">			if(i&amp;&amp;j)</span><br><span class="line">				res[i][j]=0;</span><br><span class="line">			else</span><br><span class="line">				res[i][j]=1;</span><br><span class="line">		&#125;</span><br><span class="line">	while(N)//快速幂部分 </span><br><span class="line">	&#123;</span><br><span class="line">		if(N&amp;1)</span><br><span class="line">		&#123;//ans=ans*res</span><br><span class="line">			for(i=0;i&lt;n;i++)</span><br><span class="line">				for(j=0;j&lt;n;j++)</span><br><span class="line">				&#123;</span><br><span class="line">					tep[i][j]=ans[0][j]*res[i][0]+ans[j][1]*res[1][i];</span><br><span class="line">				&#125;</span><br><span class="line">			for(i=0;i&lt;n;i++)</span><br><span class="line">				for(j=0;j&lt;n;j++)</span><br><span class="line">					ans[i][j]=tep[i][j];</span><br><span class="line">		&#125;//res=res*res</span><br><span class="line">		for(i=0;i&lt;n;i++)</span><br><span class="line">			for(j=0;j&lt;n;j++)</span><br><span class="line">			&#123;</span><br><span class="line">				tep[i][j]=res[0][j]*res[i][0]+res[j][1]*res[1][i];</span><br><span class="line">			&#125;</span><br><span class="line">		for(i=0;i&lt;n;i++)</span><br><span class="line">			for(j=0;j&lt;n;j++)</span><br><span class="line">				res[i][j]=tep[i][j];</span><br><span class="line">		N&gt;&gt;=1;</span><br><span class="line">	&#125;</span><br><span class="line">	return ans[0][0];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<hr>
<p>至此我要介绍的全部方法都结束了。其实，如果认真看下来，可能都有点忘了我们最初只是为了算出爬楼梯的方法数。我之所以要写这么多方法是因为我觉得这些方法远比一道题的最优解重要。因为有些方法可能在这道题里并不是最优的解法，但在别的题里或许是最优的解。我们应该能理解并使用这些方法，哪怕是最开始的贪婪算法，只要掌握了思想，其实在许多地方是有用武之地的。</p>
<p>总结：爬楼梯问题在本质上来说就是将整体最优解转化为子问题最优解，可选方案包括动态规划与贪心算法，<br>具体到本问题中斐波那契数列的应用以及简化，都是动态规划在此情形下的数学优化，而使用排列组合方法则是贪心算法的体现，如果将问题的特征更一般化，通用的解决方案还得从本质的动态规划和贪心入手，而动态规划相比于贪心则更容易实现，且贪心的每一个操作都会对结果产生直接影响，而动态规划可以把之前的数据保存下来可以回退，数据更立体，可操作性更强。</p>
<p><em>匆忙总结，如有错误,海涵见谅。</em>😋</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

      <div>
       
      </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="X">
            
              <p class="site-author-name" itemprop="name">X</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">23</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              

              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">X</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v6.6.0</div>



<div class="powered-by">
  <i class="fa fa-child" font="" style="font-size:26px;"></i>
  <span id="busuanzi_container_site_uv">
    本站访客数:<span id="busuanzi_value_site_uv"></span>
  </span>
</div>

        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=6.6.0"></script>

  <script src="/js/src/motion.js?v=6.6.0"></script>



  
  


  <script src="/js/src/affix.js?v=6.6.0"></script>

  <script src="/js/src/schemes/pisces.js?v=6.6.0"></script>



  

  


  <script src="/js/src/bootstrap.js?v=6.6.0"></script>



  



  











  





  

  

  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {equationNumbers: { autoNumber: "AMS" }}
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
.MathJax_Display {
  overflow: auto hidden;
}
</style>

    
  


  

  

  

  

  

  

  

  

</body>
</html>
